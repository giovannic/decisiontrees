Implentation

Cross validation

We decided to use fold sizes of floor(|examples|/folds), which in this case was floor(1004/10) = 100, to get the largest most evenly sized folds.

The data was then iterated over 10 times producing 6 sets of trees trained with 904 examples to predict 100 results per set. No predictions are made for the last 4 examples.

The decision trees are trained by rooting the attribute which will result in the greatest information gain so we can reduce the size of our tree. We calculate the information gain by first calculating the entropy of the current set of examples. For each attribute we then calculate the entropies for the examples produced for each possible outcome, 0 or 1, and weight them on the fraction of the examples they will produce. These entropies are then subtracted from the total gain to give the gain. The attribute with the largest gain is selected.

On top of this we have a threshold for information gain. When selecting the best attribute, if the maximum information gain is below 0.07 we produce a leaf instead. This reduces overfitting and makes the tree smaller, more memory efficient. This has resulted in better F1 measure.

After our tree has been built [reduced error pruning]

We make our predictions by walking the 6 trees, ignoring results with no successes across the trees and resolving conflicts in various ways: randomly, on common outcomes and on the depth of the successful leaf, discussed in the ambiguity problem section.

Our predictions are then aligned with the corresponding target data, y, and merged into a single vector so average results can be computed.

A confusion matrix is formed using the built-in function "confusionmat".

Our recall rates, precision rates and the f1-measure are then computed for each emotion from the confusion matrix in the following way:

classification rate = |classified| / |predictions| * 100

recall rate (e) = confusion matrix(e,e) / sum over i {confusion matrix(e,i)} * 100
precision rate (e) = confusion matrix(e,e) / sum over j {confusion matrix(j, e)} * 100

f1(e) = 2 * precision rates(e) * recall rate(e) / (precision rates(e) + recall rate(e))



pruning

The above graph shows how the number of misclassifications vary with the size of the decision tree. The errors shown by the cross validation(blue) shows an average of the errors made over the folds. The resubstitution error(red) shows the proportion of which is caused by pruning, i.e. substituting a sub tree with a smaller one to give a looser fit and make the overall tree smaller.

As more pruning takes place, more generalisations are made by the tree, the sizegets smaller and the cost increases sharply as the tree quickly loses specificity. As less pruning takes place the tree gradually increases in cost, despite the reduction in resubstitution cost, as it overfits the training data and cannot generalise to new data.

The optimal tree size is with around 40 nodes since it strikes a balance with the pros and cons mentioned above.


It was created using the pruning_example functionwhich creates the tree which both pruning methods use and prunes it using both methods. The method then plots the graph seen above. It can be seen that any amount of pruning increases the cost in the case of resubstition, with the ideal (least cost) number of nodes being 200. For cross validation however, pruning appears to have a sweet spot when around 40 nodes are remaining. This occurs because. 
